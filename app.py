import streamlit as st
import google.generativeai as genai
import json
import random
import time
import re
from collections import Counter

# --- 1. CONFIGURACI√ìN VISUAL ROBUSTA ---
st.set_page_config(page_title="Entrenador Legal TIT√ÅN v5.3", page_icon="‚öñÔ∏è", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; font-weight: bold; height: 3.5em; transition: all 0.3s;}
    .stButton>button:hover {transform: scale(1.02);}
    .narrative-box {
        background-color: #f8f9fa; 
        padding: 25px; 
        border-radius: 12px; 
        border-left: 6px solid #1f618d; 
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin-bottom: 25px;
        font-family: 'Georgia', serif;
    }
    .question-card {
        background-color: #ffffff;
        padding: 20px;
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        margin-bottom: 15px;
    }
    .status-bar {font-weight: bold; color: #2e86c1;}
</style>
""", unsafe_allow_html=True)

# --- 2. CEREBRO L√ìGICO (TIT√ÅN CANDADO v5.3) ---
class LegalEngineTITAN:
    def __init__(self):
        # Memoria de Contenidos
        self.chunks = []           
        self.chunk_origins = {}    
        
        # Memoria de Progreso 
        self.mastery_tracker = {}  
        self.failed_indices = set()
        self.mistakes_log = []
        self.feedback_history = []
        
        # Estado Actual
        self.current_data = None
        self.current_chunk_idx = -1
        self.entity = ""
        self.simulacro_mode = False
        
        # Configuraci√≥n IA
        self.model = None
        self.current_temperature = 0.2 

    def configure_api(self, key):
        try:
            genai.configure(api_key=key)
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            selected = next((m for m in models if 'gemini-1.5-flash' in m.lower()), None)
            if not selected: selected = next((m for m in models if 'flash' in m.lower()), models[0])
            self.model = genai.GenerativeModel(selected)
            return True, f"Conectado al Cerebro: {selected.split('/')[-1]}"
        except Exception as e:
            return False, f"Error Cr√≠tico API: {str(e)}"

    def process_law(self, text, append=False):
        text = text.replace('\r', '')
        if len(text) < 100: return 0
        new_chunks = []
        step = 5500 
        for i in range(0, len(text), step):
            chunk = text[i:i+step]
            new_chunks.append(chunk)
            
        if not append:
            self.chunks = new_chunks
            self.mastery_tracker = {i: 0 for i in range(len(self.chunks))}
            self.failed_indices = set()
            self.mistakes_log = []
        else:
            start_index = len(self.chunks)
            self.chunks.extend(new_chunks)
            for i in range(len(new_chunks)):
                real_idx = start_index + i
                self.mastery_tracker[real_idx] = 0 
        
        return len(new_chunks)

    def get_stats(self):
        if not self.chunks: return 0, 0, 0
        total_chunks = len(self.chunks)
        goal_score = total_chunks * 3 
        current_score = sum(self.mastery_tracker.values())
        percentage = int((current_score / goal_score) * 100) if goal_score > 0 else 0
        pending_reviews = len(self.failed_indices)
        return percentage, pending_reviews, total_chunks

    def get_calibration_prompt(self):
        """Genera instrucciones AGRESIVAS basadas en el feedback."""
        if not self.feedback_history: return "Modo: Est√°ndar."
        
        counts = Counter(self.feedback_history)
        instructions = []
        
        # --- CALIBRACI√ìN AGRESIVA (CANDADO DE LECTURA v5.3) ---
        
        # 1. DESCONEXI√ìN (Lo que detectaste)
        if counts['desconectado'] > 0:
            instructions.append("üîó CANDADO DE LECTURA EXTREMO: Si el usuario puede responder SIN leer el caso, FALLAS. La pregunta DEBE obligatoriamente mencionar una variable √∫nica del relato (ej: 'Dado que la falta ocurri√≥ un domingo...', 'Considerando que Mar√≠a es provisional...'). Prohibido preguntar definiciones te√≥ricas.")

        # 2. TAMA√ëO
        if counts['sesgo_longitud'] > 0:
            instructions.append("üõë ALERTA DE FORMATO: Las opciones A, B y C deben tener EXACTAMENTE la misma cantidad de palabras (+/- 2 palabras).")

        # 3. RESPUESTA OBVIA
        if counts['respuesta_obvia'] > 0:
            instructions.append("üíÄ DIFICULTAD T√âCNICA: Los distractores deben ser trampas sutiles (cambiar un n√∫mero, un plazo o una palabra). No pongas opciones absurdas.")
        
        # 4. FACILISMO
        if counts['pregunta_facil'] > 0:
            instructions.append("‚ö†Ô∏è EXIGENCIA DE LECTURA: La respuesta correcta DEBE estar escondida en un detalle peque√±o del texto.")
            
        # 5. REPETICI√ìN
        if counts['repetitivo'] > 0:
            self.current_temperature = 0.7 
            instructions.append("üîÑ VARIEDAD: Genera una situaci√≥n f√°ctica RADICALMENTE DIFERENTE.")
        
        # 6. ALUCINACI√ìN
        if counts['alucinacion'] > 0:
            self.current_temperature = 0.0 
            instructions.append("‚õî SOLO HECHOS DEL TEXTO: Si la norma no lo dice, no lo preguntes.")

        return "\n".join(instructions)

    def _safe_call(self, prompt):
        retries = 3
        wait = 5
        config = {"temperature": self.current_temperature, "response_mime_type": "application/json"}
        
        for i in range(retries):
            try:
                response = self.model.generate_content(prompt, generation_config=config)
                return response.text
            except Exception as e:
                if "429" in str(e) or "quota" in str(e).lower():
                    st.toast(f"‚è≥ Tr√°fico alto IA. Reintentando en {wait}s...", icon="üö¶")
                    time.sleep(wait)
                    wait *= 2
                else:
                    return None
        return None

    def generate_case(self):
        if not self.chunks: return {"error": "‚ö†Ô∏è Carga una norma primero."}
        
        # Selecci√≥n de bloque
        if self.simulacro_mode:
            idx = random.choice(range(len(self.chunks)))
        else:
            if self.failed_indices:
                if random.random() < 0.6: idx = random.choice(list(self.failed_indices))
                else:
                    pending = [k for k,v in self.mastery_tracker.items() if v < 3]
                    idx = random.choice(pending) if pending else random.choice(range(len(self.chunks)))
            else:
                pending = [k for k,v in self.mastery_tracker.items() if v < 3]
                idx = random.choice(pending) if pending else random.choice(range(len(self.chunks)))
        
        self.current_chunk_idx = idx
        text_chunk = self.chunks[idx]
        current_level = self.mastery_tracker.get(idx, 0)
        
        lentes = ["NIVEL 1: CONCEPTUAL", "NIVEL 2: PROCEDIMENTAL", "NIVEL 3: SANCIONATORIO", "NIVEL 4: SITUACIONAL"]
        lente_actual = lentes[min(current_level, 3)]
        contexto = f"CONTEXTO: {self.entity.upper()}" if self.entity else ""
        
        calibracion_activa = self.get_calibration_prompt()

        # --- PROMPT MEJORADO v5.3 (CANDADO DE LECTURA) ---
        prompt = f"""
        ACT√öA COMO UN EXPERTO DISE√ëADOR DE PRUEBAS CNSC (FUENTE CERRADA).
        
        TEXTO FUENTE:
        ---------------------------------------------------------
        "{text_chunk[:6000]}"
        ---------------------------------------------------------
        
        MISI√ìN: Crear un CASO SITUACIONAL con 4 PREGUNTAS TIPO SELECCI√ìN M√öLTIPLE.
        
        REGLA DE ORO (CANDADO DE LECTURA):
        La pregunta DEBE obligar al usuario a leer los detalles del caso.
        * MAL: "¬øCu√°l es el plazo de apelaci√≥n?" (Esto es te√≥rico, se responde sin leer).
        * BIEN: "Dado que la notificaci√≥n fue el **viernes 15**, ¬øcu√°ndo vence el plazo de **Pedro**?" (Esto obliga a leer).
        
        INSTRUCCIONES:
        1. **FOCO:** {lente_actual}. {contexto}.
        2. **FUENTE CERRADA:** Respalda todo en el texto.
        3. **ANTI-SESGO:** Opciones A, B, C del mismo largo visual.
        
        !!! INSTRUCCIONES DE CALIBRACI√ìN !!!
        {calibracion_activa}
        
        FORMATO JSON OBLIGATORIO:
        {{
            "narrativa_caso": "Narraci√≥n detallada con fechas, nombres y situaciones...",
            "preguntas": [
                {{
                    "enunciado": "Pregunta vinculada a los hechos...",
                    "opciones": {{ "A": "Opci√≥n 1", "B": "Opci√≥n 2", "C": "Opci√≥n 3" }},
                    "respuesta": "A",
                    "explicacion": "..."
                }},
                ... (Total 4 preguntas)
            ]
        }}
        """
        
        res_json = self._safe_call(prompt)
        if not res_json: return {"error": "Error de conexi√≥n."}
        
        try:
            clean_text = res_json.strip()
            if "```" in clean_text:
                clean_text = re.search(r'```(?:json)?(.*?)```', clean_text, re.DOTALL)
                if clean_text: clean_text = clean_text.group(1).strip()
            return json.loads(clean_text)
        except:
            return {"error": "Error procesando respuesta IA."}

# --- 3. INICIALIZACI√ìN ---
if 'engine' not in st.session_state: st.session_state.engine = LegalEngineTITAN()
if 'page' not in st.session_state: st.session_state.page = 'setup'
if 'q_idx' not in st.session_state: st.session_state.q_idx = 0
if 'answered' not in st.session_state: st.session_state.answered = False

engine = st.session_state.engine

# --- 4. INTERFAZ ---
with st.sidebar:
    st.title("‚öôÔ∏è Panel de Control")
    key = ""
    if "GEMINI_KEY" in st.secrets:
        key = st.secrets["GEMINI_KEY"]
        st.success("üîë Licencia Activa")
    else:
        key = st.text_input("Ingresa tu API Key:", type="password")
    
    if key and not engine.model:
        ok, msg = engine.configure_api(key)
        if not ok: st.error(msg)
    
    st.divider()
    engine.entity = st.text_input("Entidad:", placeholder="Ej: Fiscal√≠a...")
    txt_input = st.text_area("Texto de la Norma:", height=200)
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚ö†Ô∏è INICIAR NUEVO", type="primary"):
            c = engine.process_law(txt_input, append=False)
            if c: 
                st.session_state.page = 'game'
                st.session_state.current_data = None
                st.rerun()
            
    with col2:
        if st.button("‚ûï AGREGAR"):
            c = engine.process_law(txt_input, append=True)
            if c: st.success(f"+{c} Bloques.")
            
    st.divider()
    if st.button("üî• MODO SIMULACRO", disabled=not engine.chunks):
        engine.simulacro_mode = True
        st.session_state.current_data = None
        st.session_state.page = 'game'
        st.rerun()
        
    st.divider()
    if engine.chunks:
        save_data = json.dumps({"chunks": engine.chunks, "mastery": engine.mastery_tracker, "failed": list(engine.failed_indices), "log": engine.mistakes_log, "feed": engine.feedback_history, "entity": engine.entity})
        st.download_button("Descargar JSON", save_data, "progreso.json", "application/json")
    
    upl = st.file_uploader("Cargar JSON", type=['json'])
    if upl:
        try:
            d = json.load(upl)
            engine.chunks = d['chunks']
            engine.mastery_tracker = {int(k):v for k,v in d['mastery'].items()}
            engine.failed_indices = set(d['failed'])
            engine.mistakes_log = d['log']
            engine.feedback_history = d['feed']
            engine.entity = d.get('entity', "")
            st.success("¬°Recuperado!")
        except: st.error("Error.")

# --- 5. JUEGO ---
if st.session_state.page == 'game':
    perc, fails, total = engine.get_stats()
    st.markdown(f"""
    <div style='display:flex; justify-content:space-between; align-items:center; background:#eee; padding:10px; border-radius:8px;'>
        <span class='status-bar'>{'üî• SIMULACRO' if engine.simulacro_mode else 'üìö ESTUDIO'}</span>
        <span class='status-bar'>DOMINIO: {perc}%</span>
        <span class='status-bar'>BLOQUES: {total}</span>
        <span class='status-bar' style='color:red'>REPASOS: {fails}</span>
    </div>
    """, unsafe_allow_html=True)
    st.progress(perc/100)

    if not st.session_state.current_data:
        with st.spinner("‚öñÔ∏è Dise√±ando caso complejo..."):
            data = engine.generate_case()
            if "error" in data:
                st.error(data['error'])
                if st.button("Reintentar"): st.rerun()
                st.stop()
            st.session_state.current_data = data
            st.session_state.q_idx = 0
            st.session_state.answered = False
            st.rerun()

    data = st.session_state.current_data
    q_idx = st.session_state.q_idx
    questions = data.get('preguntas', [])

    st.markdown(f"""
    <div class="narrative-box">
        <h4>üìú Caso Situacional</h4>
        <p style="font-size:1.1em; line-height:1.6;">{data.get('narrativa_caso', 'Error narrativo.')}</p>
    </div>
    """, unsafe_allow_html=True)

    if q_idx < len(questions):
        q = questions[q_idx]
        with st.container():
            st.markdown(f"### üîπ Pregunta {q_idx + 1} de {len(questions)}")
            st.markdown(f"##### {q['enunciado']}")
            opts = q['opciones']
            op_list = [f"A) {opts.get('A','')}", f"B) {opts.get('B','')}", f"C) {opts.get('C','')}"]
            
            with st.form(key=f"q_form_{q_idx}"):
                selection = st.radio("Respuesta:", op_list, index=None)
                if st.form_submit_button("‚úÖ Validar Respuesta") and selection:
                    letter = selection[0]
                    correct = q['respuesta'].upper()
                    if letter == correct:
                        st.success("‚úÖ ¬°CORRECTO!")
                        if engine.current_chunk_idx in engine.failed_indices: engine.failed_indices.remove(engine.current_chunk_idx)
                    else:
                        st.error(f"‚ùå INCORRECTO. Era la {correct}.")
                        engine.failed_indices.add(engine.current_chunk_idx)
                        engine.mistakes_log.append({"pregunta": q['enunciado'], "error": letter, "correcta": correct})
                    st.info(f"üí° {q['explicacion']}")
                    st.session_state.answered = True

        if st.session_state.answered:
            col_nav, col_rep = st.columns([1, 1])
            with col_nav:
                if q_idx < len(questions) - 1:
                    if st.button("‚è≠Ô∏è Siguiente Pregunta"):
                        st.session_state.q_idx += 1
                        st.session_state.answered = False
                        st.rerun()
                else:
                    if st.button("üîÑ TERMINAR CASO"):
                        if not engine.simulacro_mode:
                            idx = engine.current_chunk_idx
                            engine.mastery_tracker[idx] = engine.mastery_tracker.get(idx, 0) + 1
                        st.session_state.current_data = None
                        st.session_state.q_idx = 0
                        st.session_state.answered = False
                        st.rerun()
            
            with col_rep:
                with st.expander("üì¢ Calibrar IA (REPORTAR FALLO)"):
                    reasons = {
                        "Se responde SIN leer el caso (Te√≥rica)": "desconectado",
                        "Respuesta muy Obvia (Regalada)": "respuesta_obvia",
                        "Opciones de diferente largo": "sesgo_longitud",
                        "Pregunta muy F√°cil": "pregunta_facil",
                        "Repetitivo": "repetitivo",
                        "Alucinaci√≥n (Invent√≥ Norma)": "alucinacion"
                    }
                    selected_reason = st.selectbox("¬øQu√© fall√≥?", list(reasons.keys()))
                    if st.button("Enviar y Ajustar"):
                        engine.feedback_history.append(reasons[selected_reason])
                        st.toast("Modo Estricto Activado. El pr√≥ximo caso ser√° m√°s dependiente.", icon="üî•")

elif st.session_state.page == 'setup':
    st.markdown("<h1>üèõÔ∏è Entrenador Legal TIT√ÅN v5.3</h1>", unsafe_allow_html=True)