import streamlit as st
import google.generativeai as genai
import json
import random
import time
import requests
import re
import io
import os
import sys
import subprocess
from collections import Counter

# ==============================================================================
# ==============================================================================
#  ü¶Ö TIT√ÅN v94: SISTEMA JUR√çDICO INTEGRAL (EDICI√ìN SUPREMA)
#  ----------------------------------------------------------------------------
#  ESTE C√ìDIGO ES LA VERSI√ìN DEFINITIVA Y COMPLETA.
#  NO BORRAR NADA. RESPETAR COMENTARIOS Y ESPACIOS.
#
#  CARACTER√çSTICAS T√âCNICAS:
#  1. MOTOR DE INTELIGENCIA SELECTIVA:
#     - Selector de Modo: El usuario define si carga "Norma" o "Gu√≠a".
#     - Segmentaci√≥n Espec√≠fica: Aplica reglas diferentes seg√∫n el tipo.
#     - Filtro Anti-√çndice: Ignora l√≠neas de tabla de contenido (Ej: "Tema ... 5").
#
#  2. GESTI√ìN DE ARCHIVOS:
#     - Lector PDF Nativo (pypdf) integrado y robusto.
#     - Procesador de Texto Manual para copias r√°pidas.
#     - Sistema de Backups JSON completo para guardar progreso.
#
#  3. PEDAGOG√çA Y CALIBRACI√ìN:
#     - Sistema "5 Capitanes" (Calibraci√≥n limpia y directa).
#     - Ordenamiento Natural (1, 2, 10...) en el men√∫ de navegaci√≥n.
#     - Barajador Inteligente de Respuestas para evitar patrones.
# ==============================================================================
# ==============================================================================


# ------------------------------------------------------------------------------
# SECCI√ìN 1: GESTI√ìN DE DEPENDENCIAS Y LIBRER√çAS EXTERNAS
# ------------------------------------------------------------------------------

# A. SISTEMA DE IA NEURONAL (Embeddings)
# Intentamos cargar librer√≠as de IA avanzada para b√∫squeda sem√°ntica.
# Si no est√°n presentes, el sistema usar√° el modo aleatorio (Fail-safe).
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    DL_AVAILABLE = True
    print("‚úÖ Cerebro Neuronal (SentenceTransformers) Activado.")
except ImportError:
    DL_AVAILABLE = False
    print("‚ö†Ô∏è Cerebro Neuronal no detectado. Se usar√° modo aleatorio.")

# B. LECTOR DE ARCHIVOS PDF (CR√çTICO PARA GU√çAS Y MANUALES)
# Intentamos cargar la librer√≠a de lectura de PDFs.
try:
    import pypdf
    PDF_AVAILABLE = True
    print("‚úÖ Lector PDF (pypdf) Activado.")
except ImportError:
    # No forzamos la instalaci√≥n autom√°tica para evitar reinicios, pero avisamos.
    PDF_AVAILABLE = False
    print("‚ö†Ô∏è Lector PDF no detectado. Solo se admitir√° texto manual.")


# ------------------------------------------------------------------------------
# SECCI√ìN 2: CONFIGURACI√ìN VISUAL Y ESTILOS (TU CSS ORIGINAL COMPLETO)
# ------------------------------------------------------------------------------
st.set_page_config(
    page_title="TIT√ÅN v94 - Supremo", 
    page_icon="‚öñÔ∏è", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Inyecci√≥n de CSS avanzado para la interfaz oscura/elegante
st.markdown("""
<style>
    /* 1. Estilo para botones principales en negro elegante */
    .stButton>button {
        width: 100%; 
        border-radius: 8px; 
        font-weight: bold; 
        height: 3.5em; 
        transition: all 0.3s ease-in-out; 
        background-color: #000000; 
        color: #ffffff;
        border: 1px solid #333;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .stButton>button:hover {
        background-color: #333333;
        color: #ffffff;
        transform: scale(1.02);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    /* 2. Caja para la narrativa del caso/norma */
    .narrative-box {
        background-color: #f8f9fa; 
        padding: 30px; 
        border-radius: 12px; 
        border-left: 6px solid #2c3e50; 
        margin-bottom: 25px;
        font-family: 'Georgia', serif; 
        font-size: 1.15em; 
        line-height: 1.6;
        color: #2c3e50;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    /* 3. Etiquetas para art√≠culos fallados (ROJO) */
    .failed-tag {
        background-color: #ffebee; 
        color: #c62828; 
        padding: 6px 12px; 
        border-radius: 20px; 
        font-size: 0.85em; 
        font-weight: 800; 
        margin-right: 6px;
        border: 1px solid #ef9a9a; 
        display: inline-block;
        margin-bottom: 8px;
    }

    /* 4. Etiquetas para art√≠culos dominados (VERDE) */
    .mastered-tag {
        background-color: #e8f5e9; 
        color: #2e7d32; 
        padding: 6px 12px; 
        border-radius: 20px; 
        font-size: 0.85em; 
        font-weight: 800; 
        margin-right: 6px;
        border: 1px solid #a5d6a7; 
        display: inline-block;
        margin-bottom: 8px;
    }
    
    /* 5. Cajas estad√≠sticas del tablero */
    .stat-box {
        text-align: center; 
        padding: 20px; 
        background: #ffffff; 
        border-radius: 12px; 
        border: 1px solid #e0e0e0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    
    /* Ajustes generales de tipograf√≠a */
    h1, h2, h3 {
        font-family: 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #111;
        font-weight: 600;
    }
    
    /* Ajuste para inputs de texto */
    .stTextInput>div>div>input {
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)


# ------------------------------------------------------------------------------
# SECCI√ìN 3: CARGA DEL MODELO DE EMBEDDINGS (CACHEADO)
# ------------------------------------------------------------------------------
@st.cache_resource
def load_embedding_model():
    """
    Carga el modelo vectorial una sola vez al inicio para optimizar rendimiento.
    Esto evita recargas innecesarias cada vez que se pulsa un bot√≥n.
    """
    if DL_AVAILABLE: 
        try:
            # Usamos un modelo ligero y r√°pido
            return SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            # Si falla, retornamos None y el sistema usar√° modo aleatorio
            return None
    return None

dl_model = load_embedding_model()


# ------------------------------------------------------------------------------
# SECCI√ìN 4: LISTA MAESTRA DE ENTIDADES COLOMBIANAS
# ------------------------------------------------------------------------------
ENTIDADES_CO = [
    "Contralor√≠a General de la Rep√∫blica", 
    "Fiscal√≠a General de la Naci√≥n",
    "Procuradur√≠a General de la Naci√≥n", 
    "Defensor√≠a del Pueblo",
    "DIAN", 
    "Registradur√≠a Nacional del Estado Civil", 
    "Consejo Superior de la Judicatura",
    "Corte Suprema de Justicia", 
    "Consejo de Estado", 
    "Corte Constitucional",
    "Polic√≠a Nacional", 
    "Ej√©rcito Nacional", 
    "Instituto Colombiano de Bienestar Familiar (ICBF)", 
    "SENA", 
    "Ministerio de Educaci√≥n Nacional", 
    "Ministerio de Salud y Protecci√≥n Social", 
    "Departamento Administrativo Nacional de Estad√≠stica (DANE)",
    "Superintendencia de Industria y Comercio",
    "Superintendencia Financiera",
    "Comisi√≥n Nacional del Servicio Civil (CNSC)",
    "Otra (Manual) / Agregar +"
]


# ==============================================================================
# ==============================================================================
#  CLASE PRINCIPAL: MOTOR JUR√çDICO TIT√ÅN
#  Esta clase encapsula toda la l√≥gica del negocio.
# ==============================================================================
# ==============================================================================
class LegalEngineTITAN:
    def __init__(self):
        # ---------------------------------------------------------
        # Variables de Almacenamiento de Datos (Estado del Sistema)
        # ---------------------------------------------------------
        self.chunks = []           # Fragmentos de texto procesado
        self.chunk_embeddings = None # Vectores matem√°ticos del texto
        self.mastery_tracker = {}  # Rastreador de dominio por bloque
        self.failed_indices = set() # √çndices de bloques fallados
        self.feedback_history = []  # Historial de calibraci√≥n (Los Capitanes)
        self.current_data = None    # Datos de la pregunta actual en pantalla
        self.current_chunk_idx = -1 # Puntero al bloque actual
        
        # ---------------------------------------------------------
        # Configuraci√≥n de Usuario (Perfil)
        # ---------------------------------------------------------
        self.entity = ""
        self.level = "Profesional" 
        self.simulacro_mode = False
        self.provider = "Unknown" 
        self.api_key = ""
        self.model = None 
        self.current_temperature = 0.3 # Creatividad baja para precisi√≥n t√©cnica
        self.last_failed_embedding = None
        self.doc_type = "Norma" # Variable CR√çTICA: Define si es Ley o Gu√≠a
        
        # ---------------------------------------------------------
        # Variables de Control Pedag√≥gico
        # ---------------------------------------------------------
        self.study_phase = "Pre-Gu√≠a" 
        self.example_question = "" 
        self.job_functions = ""    
        self.thematic_axis = "General"
        self.structure_type = "T√©cnico / Normativo (Sin Caso)" 
        self.questions_per_case = 1 
        
        # ---------------------------------------------------------
        # Mapa de Documento (√çndice Din√°mico)
        # ---------------------------------------------------------
        self.sections_map = {} 
        self.active_section_name = "Todo el Documento"
        
        # ---------------------------------------------------------
        # Sistema Francotirador & Sem√°foro
        # ---------------------------------------------------------
        self.seen_articles = set()      # Art√≠culos ya preguntados en esta sesi√≥n
        self.failed_articles = set()    # Lista Roja (Pendientes de repaso)
        self.mastered_articles = set()  # Lista Verde (Dominados)
        self.temporary_blacklist = set() # Lista Negra (Bot√≥n Saltar)
        self.current_article_label = "General"

    # --------------------------------------------------------------------------
    # M√âTODO: CONFIGURACI√ìN DE API
    # Detecta autom√°ticamente qu√© llave ingres√≥ el usuario.
    # --------------------------------------------------------------------------
    def configure_api(self, key):
        key = key.strip()
        self.api_key = key
        
        if key.startswith("gsk_"):
            self.provider = "Groq"
            return True, "üöÄ Motor GROQ Activado (Velocidad S√≥nica)"
        elif key.startswith("sk-") or key.startswith("sk-proj-"): 
            self.provider = "OpenAI"
            return True, "ü§ñ Motor CHATGPT (GPT-4o) Activado (Precisi√≥n M√°xima)"
        else:
            self.provider = "Google"
            try:
                genai.configure(api_key=key)
                model_list = genai.list_models()
                models = [m.name for m in model_list if 'generateContent' in m.supported_generation_methods]
                
                # Buscamos el mejor modelo disponible (Pro o Flash)
                target = next((m for m in models if 'gemini-1.5-pro' in m), 
                         next((m for m in models if 'flash' in m), models[0]))
                
                self.model = genai.GenerativeModel(target)
                return True, f"üß† Motor GOOGLE ({target}) Activado"
            except Exception as e:
                return False, f"Error con la llave: {str(e)}"

    # --------------------------------------------------------------------------
    # M√âTODO: SEGMENTACI√ìN INTELIGENTE SELECTIVA (EL CEREBRO DEL LECTOR v94)
    # Aqu√≠ aplicamos la l√≥gica separada que pediste: Norma vs Gu√≠a.
    # --------------------------------------------------------------------------
    def smart_segmentation(self, full_text):
        """
        Divide el texto bas√°ndose EXCLUSIVAMENTE en el tipo de documento seleccionado.
        Esto evita que el sistema se confunda tratando de adivinar.
        """
        lineas = full_text.split('\n')
        secciones = {"Todo el Documento": []} 
        
        # Variables de estado para seguimiento de jerarqu√≠a
        active_label = None

        # --- PATRONES REGEX PARA LEYES (NORMA) ---
        p_libro = r'^\s*(LIBRO)\.?\s+[IVXLCDM]+\b'
        p_tit = r'^\s*(T√çTULO|TITULO)\.?\s+[IVXLCDM]+\b' 
        p_cap = r'^\s*(CAP√çTULO|CAPITULO)\.?\s+[IVXLCDM0-9]+\b'
        p_art = r'^\s*(ART√çCULO|ARTICULO|ART)\.?\s*\d+'
        
        # --- PATRONES REGEX PARA GU√çAS (INDICES NUM√âRICOS) ---
        # Detecta: "1. Texto" o "10. Texto"
        p_idx_1 = r'^\s*(\d+)\.\s+([A-Z√Å√â√ç√ì√ö√ë].+)'      
        # Detecta: "1.1 Texto" o "2.3.4 Texto"
        p_idx_2 = r'^\s*(\d+\.\d+)\.?\s+([A-Z√Å√â√ç√ì√ö√ë].+)' 
        
        # --- FILTRO ANTI-√çNDICE (EL CORTAFUEGOS) ---
        # Detecta l√≠neas que terminan en n√∫mero y tienen muchos puntos (Tabla de Contenido)
        # Ej: "5. Desarrollo ........................................... 7"
        p_basura_indice = r'\.{4,}\s*\d+\s*$' 

        for linea in lineas:
            linea_limpia = linea.strip()
            if not linea_limpia: continue
            
            # -------------------------------------------------------
            # CAMINO 1: SI ES UNA GU√çA T√âCNICA O MANUAL
            # -------------------------------------------------------
            if self.doc_type == "Gu√≠a T√©cnica / Manual":
                # 1. Aplicamos el Filtro Anti-√çndice INMEDIATAMENTE
                # Si la l√≠nea tiene "..... 7", se muere aqu√≠.
                if re.search(p_basura_indice, linea_limpia): 
                    continue 
                
                # 2. Buscamos T√≠tulos Num√©ricos (Nivel 1)
                if re.match(p_idx_1, linea_limpia):
                    m = re.match(p_idx_1, linea_limpia)
                    active_label = f"CAP√çTULO {m.group(1)}: {m.group(2)[:80]}"
                    if active_label not in secciones: secciones[active_label] = []
                
                # 3. Buscamos Subt√≠tulos Num√©ricos (Nivel 2)
                elif re.match(p_idx_2, linea_limpia):
                    m = re.match(p_idx_2, linea_limpia)
                    active_label = f"SECCI√ìN {m.group(1)}: {m.group(2)[:80]}"
                    if active_label not in secciones: secciones[active_label] = []

            # -------------------------------------------------------
            # CAMINO 2: SI ES UNA NORMA (LEY, DECRETO, C√ìDIGO)
            # -------------------------------------------------------
            elif self.doc_type == "Norma (Leyes/Decretos)":
                # Aqu√≠ NO aplicamos el filtro anti-√≠ndice tan agresivo.
                
                if re.match(p_libro, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                    
                elif re.match(p_tit, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                    
                elif re.match(p_cap, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                
                # Nota: Los art√≠culos se detectan para el "Francotirador", pero no crean una secci√≥n nueva
                # en el men√∫ desplegable para no saturarlo si la ley tiene 500 art√≠culos.

            # -------------------------------------------------------
            # GUARDADO DE DATOS (HERENCIA)
            # -------------------------------------------------------
            # El texto siempre va al "Todo el Documento"
            secciones["Todo el Documento"].append(linea)
            
            # Si hay una etiqueta activa (Cap√≠tulo, T√≠tulo, etc.), guardamos la l√≠nea ah√≠ tambi√©n
            if active_label: 
                secciones[active_label].append(linea)

        # Filtramos secciones vac√≠as o con muy poco texto (ruido)
        return {k: "\n".join(v) for k, v in secciones.items() if len(v) > 20}

    # --------------------------------------------------------------------------
    # M√âTODO: PROCESAMIENTO Y CHUNKING (DIVISI√ìN)
    # --------------------------------------------------------------------------
    def process_law(self, text, axis_name, doc_type_input):
        """
        Prepara el texto para ser consumido por la IA.
        Recibe el TIPO DE DOCUMENTO del usuario.
        """
        text = text.replace('\r', '')
        if len(text) < 100: return 0
        
        self.thematic_axis = axis_name 
        self.doc_type = doc_type_input # Guardamos la elecci√≥n vital (Norma vs Gu√≠a)
        self.sections_map = self.smart_segmentation(text)
        
        # Bloques de 50.000 caracteres (Balance entre contexto y memoria)
        self.chunks = [text[i:i+50000] for i in range(0, len(text), 50000)]
        self.mastery_tracker = {i: 0 for i in range(len(self.chunks))}
        
        if dl_model: 
            with st.spinner("üß† Generando mapa neuronal del documento..."): 
                self.chunk_embeddings = dl_model.encode(self.chunks)
        return len(self.chunks)

    def update_chunks_by_section(self, section_name):
        """
        Permite al usuario estudiar solo una parte espec√≠fica.
        """
        if section_name in self.sections_map:
            texto_seccion = self.sections_map[section_name]
            self.chunks = [texto_seccion[i:i+50000] for i in range(0, len(texto_seccion), 50000)]
            self.mastery_tracker = {i: 0 for i in range(len(self.chunks))}
            self.active_section_name = section_name
            
            if dl_model: 
                self.chunk_embeddings = dl_model.encode(self.chunks)
            
            # Limpieza de memoria temporal
            self.seen_articles.clear()
            self.temporary_blacklist.clear()
            return True
        return False

    # --------------------------------------------------------------------------
    # M√âTODO: ESTAD√çSTICAS
    # --------------------------------------------------------------------------
    def get_stats(self):
        if not self.chunks: return 0, 0, 0
        total = len(self.chunks)
        SCORE_THRESHOLD = 50 
        score = sum([min(v, SCORE_THRESHOLD) for v in self.mastery_tracker.values()])
        perc = int((score / (total * SCORE_THRESHOLD)) * 100) if total > 0 else 0
        return min(perc, 100), len(self.failed_indices), total

    def get_strict_rules(self):
        return "1. NO SPOILERS: La pregunta NO debe dar la respuesta. 2. DEPENDENCIA: Obligatorio leer el texto."

    def get_calibration_instructions(self):
        return """
        INSTRUCCIONES DE FORMATO:
        1. NO REPETIR TEXTO: El 'enunciado' NO debe repetir lo que ya dice la 'narrativa_caso'.
        2. NO CHIVATEAR: No digas "Seg√∫n el punto 2.1". Di "Seg√∫n la gu√≠a".
        """

    # --------------------------------------------------------------------------
    # M√âTODO: GENERADOR DE CASOS (ESTRATEGIA SELECTIVA v94)
    # --------------------------------------------------------------------------
    def generate_case(self):
        """
        El cerebro de la operaci√≥n. 
        Usa el TIPO DE DOCUMENTO para decidir qu√© buscar en el texto.
        """
        if not self.api_key: return {"error": "Falta Llave API"}
        if not self.chunks: return {"error": "Falta Documento Cargado"}
        
        # 1. Selecci√≥n de Bloque (Chunk)
        idx = -1
        # L√≥gica de recuperaci√≥n de errores (Si hay embeddings)
        if self.last_failed_embedding is not None and self.chunk_embeddings is not None and not self.simulacro_mode:
            sims = cosine_similarity([self.last_failed_embedding], self.chunk_embeddings)[0]
            candidatos = [(i, s) for i, s in enumerate(sims) if self.mastery_tracker.get(i, 0) < 3]
            candidatos.sort(key=lambda x: x[1], reverse=True)
            if candidatos: idx = candidatos[0][0]
        
        if idx == -1: idx = random.choice(range(len(self.chunks)))
        
        self.current_chunk_idx = idx
        texto_base = self.chunks[idx]
        
        # 2. ESTRATEGIA DE FRANCOTIRADOR SELECTIVA
        matches = []
        
        if self.doc_type == "Norma (Leyes/Decretos)":
            # ESTRATEGIA A: Buscar "ART√çCULO X" (Para leyes)
            p_art = r'^\s*(?:ART√çCULO|ARTICULO|ART)\.?\s*(\d+[A-Z]?)'
            matches = list(re.finditer(p_art, texto_base, re.I | re.M))
            
        elif self.doc_type == "Gu√≠a T√©cnica / Manual":
            # ESTRATEGIA B: Buscar "√çNDICES NUM√âRICOS" (1., 1.1) (Para Gu√≠as)
            p_idx = r'^\s*(\d+\.\d+|\d+\.)\s+([A-Z√Å√â√ç√ì√ö√ë].+)'
            matches = list(re.finditer(p_idx, texto_base, re.M))

        texto_final_ia = texto_base
        self.current_article_label = "General / Sin Estructura Detectada"
        
        if matches:
            # Filtro Francotirador: Quitar lo ya visto o bloqueado
            candidatos = [m for m in matches if m.group(0).strip() not in self.seen_articles and m.group(0).strip() not in self.temporary_blacklist]
            
            if not candidatos:
                # Si se acabaron los nuevos, repetimos los no bloqueados
                candidatos = [m for m in matches if m.group(0).strip() not in self.temporary_blacklist]
                if not candidatos: 
                    # Si todo est√° bloqueado, reseteamos lista negra
                    candidatos = matches
                    self.temporary_blacklist.clear()
                self.seen_articles.clear()
            
            sel = random.choice(candidatos)
            start = sel.start()
            idx_m = matches.index(sel)
            
            # Cortamos hasta el siguiente elemento para aislar el tema
            end = matches[idx_m+1].start() if idx_m+1 < len(matches) else min(len(texto_base), start+4000)
            
            texto_final_ia = texto_base[start:end] 
            self.current_article_label = sel.group(0).strip()[:60] 
            
            # 3. MICRO-SEGMENTACI√ìN (Universal)
            # Busca listas internas (a, b, c) o numerales internos (1, 2, 3) dentro del bloque seleccionado
            p_sub = r'(^\s*\d+\.\s+|^\s*[a-z]\)\s+|^\s*[A-Z][a-zA-Z\s]{2,50}[:\.])'
            subs = list(re.finditer(p_sub, texto_final_ia, re.M))
            
            if len(subs) > 1:
                s = random.choice(subs)
                s_start = s.start()
                s_end = subs[subs.index(s)+1].start() if subs.index(s)+1 < len(subs) else len(texto_final_ia)
                
                # Le damos contexto + el fragmento espec√≠fico
                texto_final_ia = f"{texto_final_ia[:150]}\n[...]\n{texto_final_ia[s_start:s_end]}"
                self.current_article_label += f" - ITEM {s.group(0).strip()[:10]}..."
        else:
            self.current_article_label = "General"
            texto_final_ia = texto_base[:4000]

        # 4. CONFIGURACI√ìN DE LOS 5 CAPITANES (CALIBRACI√ìN)
        feed_instr = ""
        if self.feedback_history:
            last = self.feedback_history[-5:]
            corr = []
            
            if "pregunta_facil" in last: 
                corr.append("ALERTA CR√çTICA: El usuario se aburre. AUMENTAR DRASTICAMENTE DIFICULTAD.")
            if "respuesta_obvia" in last: 
                corr.append("ALERTA CR√çTICA: Respuestas obvias detectadas. USAR TRAMPAS L√ìGICAS.")
            if "spoiler" in last: 
                corr.append("ALERTA CR√çTICA: Spoilers detectados. SIN PISTAS EN ENUNCIADO.")
            if "desconexion" in last: 
                corr.append("ALERTA CR√çTICA: Pregunta desconectada. APEGARSE AL TEXTO AL 100%.")
            if "sesgo_longitud" in last: 
                corr.append("ALERTA CR√çTICA: Patr√≥n de longitud detectado. EQUILIBRAR OPCIONES.")
            
            if corr: feed_instr = "CORRECCIONES PRIORITARIAS DEL USUARIO: " + " ".join(corr)

        # 5. CONSTRUCCI√ìN DEL PROMPT FINAL
        prompt = f"""
        ACT√öA COMO EXPERTO EN CONCURSOS (NIVEL {self.level.upper()}). 
        ENTIDAD: {self.entity.upper()}.
        TIPO DE DOCUMENTO: {self.doc_type.upper()}.
        ESTILO: {self.structure_type}.
        {feed_instr}
        
        Genera {self.questions_per_case} preguntas (A,B,C,D) bas√°ndote EXCLUSIVAMENTE en el texto proporcionado.
        
        TEXTO DE ESTUDIO:
        "{texto_final_ia}"
        
        REGLAS DE ORO:
        1. 4 OPCIONES (A,B,C,D). Una sola correcta.
        2. EXPLICACI√ìN DETALLADA por opci√≥n (Por qu√© es correcta y por qu√© las otras no).
        3. TIP MEMORIA: Mnemotecnia corta o palabra clave.
        
        EJEMPLO DE ESTILO A COPIAR: 
        '''{self.example_question}'''
        
        FORMATO JSON OBLIGATORIO:
        {{
            "articulo_fuente": "REFERENCIA EXACTA (Ej: Art 5 o Punto 2.1)",
            "narrativa_caso": "Contexto situacional o normativo...",
            "preguntas": [
                {{
                    "enunciado": "...", 
                    "opciones": {{
                        "A": "...",
                        "B": "...",
                        "C": "...",
                        "D": "..."
                    }}, 
                    "respuesta": "A", 
                    "tip_memoria": "...", 
                    "explicaciones": {{
                        "A": "...",
                        "B": "...",
                        "C": "...",
                        "D": "..."
                    }}
                }}
            ]
        }}
        """
        
        # 6. LLAMADA A LA API (CON SISTEMA DE REINTENTOS)
        attempts = 0
        while attempts < 3:
            try:
                # Proveedor OpenAI
                if self.provider == "OpenAI":
                    h = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
                    d = {"model": "gpt-4o", "messages": [{"role":"system","content":"JSON ONLY"},{"role":"user","content":prompt}], "response_format": {"type": "json_object"}}
                    r = requests.post("https://api.openai.com/v1/chat/completions", headers=h, json=d)
                    txt_resp = r.json()['choices'][0]['message']['content']
                
                # Proveedor Google
                elif self.provider == "Google":
                    res = self.model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
                    txt_resp = res.text.strip()
                
                # Proveedor Groq
                else: 
                    h = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
                    d = {"model": "llama-3.3-70b-versatile", "messages": [{"role":"system","content":"JSON ONLY"},{"role":"user","content":prompt}]}
                    r = requests.post("https://api.groq.com/openai/v1/chat/completions", headers=h, json=d)
                    txt_resp = r.json()['choices'][0]['message']['content']

                # Limpieza de Markdown (Si la IA responde con ```json ... ```)
                if "```" in txt_resp: 
                    match = re.search(r'```(?:json)?(.*?)```', txt_resp, re.DOTALL)
                    if match: txt_resp = match.group(1).strip()
                
                final_json = json.loads(txt_resp)
                
                # Actualizar etiqueta si la IA detect√≥ mejor la fuente
                if "articulo_fuente" in final_json and "ITEM" not in self.current_article_label:
                    # Si la etiqueta actual es gen√©rica, adoptamos la de la IA
                    if "General" in self.current_article_label:
                        self.current_article_label = final_json["articulo_fuente"].upper()

                # BARAJADOR INTELIGENTE (SHUFFLE)
                # Esto evita que la respuesta correcta sea siempre la 'A' o la 'C'
                for q in final_json['preguntas']:
                    ops = list(q['opciones'].items())
                    ans_txt = q['opciones'][q['respuesta']]
                    exps = q.get('explicaciones', {})
                    
                    # Creamos objetos completos antes de barajar
                    items = [{"t":v, "e":exps.get(k,"."), "ok":(v==ans_txt)} for k,v in ops]
                    random.shuffle(items)
                    
                    new_ops = {}
                    new_ans = "A"
                    exp_txt = ""
                    lets = ['A','B','C','D']
                    
                    for i, it in enumerate(items):
                        if i < 4:
                            l = lets[i]
                            new_ops[l] = it["t"]
                            if it["ok"]: new_ans = l
                            
                            icon = "‚úÖ CORRECTA" if it["ok"] else "‚ùå INCORRECTA"
                            exp_txt += f"**({l}) {icon}:** {it['e']}\n\n"
                    
                    q['opciones'] = new_ops
                    q['respuesta'] = new_ans
                    q['explicacion'] = exp_txt
                    q['tip_final'] = q.get('tip_memoria', "")
                
                return final_json
            except Exception as e: 
                time.sleep(1)
                attempts += 1
        
        return {"error": "Servidor Saturado o Error de JSON. Por favor, reintenta."}


# ==============================================================================
# ==============================================================================
#  INTERFAZ DE USUARIO (FRONTEND STREAMLIT)
#  Aqu√≠ se construye la p√°gina web visible.
# ==============================================================================
# ==============================================================================
if 'engine' not in st.session_state: st.session_state.engine = LegalEngineTITAN()
if 'case_id' not in st.session_state: st.session_state.case_id = 0
if 'page' not in st.session_state: st.session_state.page = 'setup'
if 'q_idx' not in st.session_state: st.session_state.q_idx = 0
if 'answered' not in st.session_state: st.session_state.answered = False
engine = st.session_state.engine

# --- BARRA LATERAL (CONFIGURACI√ìN) ---
with st.sidebar:
    st.title("ü¶Ö TIT√ÅN v94 (Selectivo)")
    st.caption("Sistema de Entrenamiento Jur√≠dico Integral")
    
    with st.expander("üîë LLAVE MAESTRA (API KEY)", expanded=True):
        key = st.text_input("Ingresa tu Key (Google/OpenAI):", type="password")
        if key:
            ok, msg = engine.configure_api(key)
            if ok: st.success(msg)
            else: st.error(msg)
    
    st.divider()
    
    # --- SELECTOR DE MODO (NUEVO EN v94) ---
    st.markdown("### üìÇ TIPO DE DOCUMENTO")
    doc_type_sel = st.radio(
        "¬øQu√© vas a estudiar?", 
        ["Norma (Leyes/Decretos)", "Gu√≠a T√©cnica / Manual"],
        help="Define c√≥mo TIT√ÅN leer√° el archivo. Norma busca Art√≠culos. Gu√≠a busca Numerales.",
        index=0
    )
    
    st.divider()

    # --- NAVEGACI√ìN (MAPA) ---
    if engine.sections_map:
        st.markdown("### üìç MAPA DEL DOCUMENTO")
        
        # ORDENAMIENTO NATURAL (1, 2, 10... y no 1, 10, 2)
        opciones_mapa = list(engine.sections_map.keys())
        if "Todo el Documento" in opciones_mapa: opciones_mapa.remove("Todo el Documento")
        
        def natural_keys(text):
            return [int(c) if c.isdigit() else c for c in re.split(r'(\d+)', text)]
        
        opciones_mapa.sort(key=natural_keys)
        opciones_mapa.insert(0, "Todo el Documento")
        
        try: idx_sec = opciones_mapa.index(engine.active_section_name)
        except: idx_sec = 0
            
        sel = st.selectbox("Saltar a secci√≥n:", opciones_mapa, index=idx_sec)
        
        if sel != engine.active_section_name: 
            engine.update_chunks_by_section(sel)
            st.toast(f"Enfoque cambiado a: {sel}", icon="üó∫Ô∏è")
            st.rerun()

    st.divider()

    # --- PESTA√ëAS DE CARGA ---
    t1, t2 = st.tabs(["üìù NUEVO DOCUMENTO", "üìÇ CARGAR BACKUP"])
    
    with t1:
        txt_pdf = ""
        # 1. CARGA DE PDF (INTEGRADA)
        if PDF_AVAILABLE:
            pdf = st.file_uploader("Subir PDF (Gu√≠a/Ley/Manual):", type=['pdf'])
            if pdf:
                try:
                    with st.spinner("üìÑ Extrayendo texto..."):
                        reader = pypdf.PdfReader(pdf)
                        for p in reader.pages: txt_pdf += p.extract_text() + "\n"
                        st.success(f"¬°Le√≠do! {len(reader.pages)} p√°ginas.")
                except Exception as e: st.error(f"Error PDF: {e}")
        else:
            st.warning("‚ö†Ô∏è Librer√≠a 'pypdf' no instalada. Solo texto manual.")
        
        # 2. CARGA MANUAL
        st.caption("O pega el texto aqu√≠:")
        txt_manual = st.text_area("Texto Manual:", height=100)
        axis = st.text_input("Tema / Eje Tem√°tico (Ej: Gu√≠a Auditor√≠a):", value=engine.thematic_axis)
        
        if st.button("üöÄ PROCESAR DOCUMENTO"):
            final = txt_pdf if txt_pdf else txt_manual
            # Pasamos el TIPO DE DOCUMENTO al procesador
            if engine.process_law(final, axis, doc_type_sel): 
                st.session_state.page = 'game'
                st.session_state.current_data = None
                st.success(f"¬°Procesado como {doc_type_sel}!")
                time.sleep(1)
                st.rerun()

    with t2:
        # 3. CARGA DE BACKUP (JSON)
        upl = st.file_uploader("Subir Backup (.json):", type=['json'])
        if upl:
            try:
                d = json.load(upl)
                engine.chunks = d['chunks']
                engine.mastery_tracker = {int(k):v for k,v in d['mastery'].items()}
                # Recuperamos listas
                engine.failed_articles = set(d.get('failed_arts', []))
                engine.mastered_articles = set(d.get('mastered_arts', []))
                st.success("Backup Restaurado")
                time.sleep(1)
                st.session_state.page = 'game'
                st.session_state.current_data = None
                st.rerun()
            except: st.error("Archivo corrupto")
    
    # --- BOT√ìN DE INICIO DE SIMULACRO ---
    if engine.chunks and st.session_state.page == 'setup':
        st.divider()
        if st.button("‚ñ∂Ô∏è INICIAR ENTRENAMIENTO", type="primary"): 
            st.session_state.page = 'game'
            st.session_state.current_data = None
            st.rerun()
            
    # --- BOT√ìN DE GUARDADO ---
    if engine.chunks:
        st.divider()
        # Preparamos datos para guardar
        save_data = {
            "chunks": engine.chunks,
            "mastery": engine.mastery_tracker,
            "failed_arts": list(engine.failed_articles),
            "mastered_arts": list(engine.mastered_articles)
        }
        st.download_button("üíæ Guardar Progreso", json.dumps(save_data), "backup_titan.json")


# --- PANTALLA PRINCIPAL (JUEGO) ---
if st.session_state.page == 'game':
    # 1. M√âTRICAS SUPERIORES
    p, f, t = engine.get_stats()
    
    st.info(f"üéØ FOCO ACTUAL: **{engine.current_article_label}**")
    
    c1, c2, c3 = st.columns(3)
    c1.metric("Dominio Total", f"{p}%")
    c2.metric("Fallos Acumulados", f"{f}")
    c3.metric("Bloques Estudiados", f"{len([x for x in engine.mastery_tracker.values() if x>0])}/{t}")
    st.progress(p/100)

    # 2. GENERACI√ìN DE PREGUNTA (Si no hay activa)
    if not st.session_state.get('current_data'):
        with st.spinner("ü§ñ Analizando documento y generando caso..."):
            d = engine.generate_case()
            if "error" in d: 
                st.error(d['error'])
                if st.button("Reintentar"): st.rerun()
            else: 
                st.session_state.current_data = d
                st.session_state.case_id += 1
                st.session_state.q_idx = 0
                st.session_state.answered = False
                st.rerun()

    # 3. VISUALIZACI√ìN DE LA PREGUNTA
    d = st.session_state.current_data
    
    # Caja de Narrativa
    st.markdown(f"<div class='narrative-box'><h4>üìú Contexto</h4>{d.get('narrativa_caso','...')}</div>", unsafe_allow_html=True)
    
    if d.get('preguntas'):
        q_list = d['preguntas']
        if st.session_state.q_idx < len(q_list):
            q = q_list[st.session_state.q_idx]
            
            with st.form(key=f"form_{st.session_state.case_id}_{st.session_state.q_idx}"):
                st.write(f"### {q['enunciado']}")
                
                # Opciones de Radio
                # Usamos una lista de opciones pre-barajadas desde la generaci√≥n
                opciones_visuales = [f"{k}) {v}" for k, v in q['opciones'].items()]
                sel = st.radio("Selecciona una opci√≥n:", opciones_visuales)
                
                c_val, c_skip = st.columns([1,1])
                submitted = c_val.form_submit_button("‚úÖ VALIDAR RESPUESTA")
                skipped = c_skip.form_submit_button("‚è≠Ô∏è SALTAR TEMA (Bloquear)")
                
                # --- L√ìGICA DE VALIDACI√ìN ---
                if submitted:
                    if not sel:
                        st.warning("Debes seleccionar una opci√≥n.")
                    else:
                        letra_seleccionada = sel.split(")")[0]
                        if letra_seleccionada == q['respuesta']: 
                            st.success("üéâ ¬°CORRECTO! Has dominado este punto.")
                            engine.mastery_tracker[engine.current_chunk_idx] += 1
                            
                            tag = f"[{engine.thematic_axis}] {engine.current_article_label}"
                            if "General" not in tag: 
                                engine.failed_articles.discard(tag)
                                engine.mastered_articles.add(tag)
                        else: 
                            st.error(f"‚ùå INCORRECTO. La respuesta correcta era la opci√≥n {q['respuesta']}.")
                            engine.failed_indices.add(engine.current_chunk_idx)
                            
                            # Guardamos vector de error si hay modelo
                            if engine.chunk_embeddings is not None:
                                engine.last_failed_embedding = engine.chunk_embeddings[engine.current_chunk_idx]
                            
                            tag = f"[{engine.thematic_axis}] {engine.current_article_label}"
                            if "General" not in tag: 
                                engine.mastered_articles.discard(tag)
                                engine.failed_articles.add(tag)
                        
                        # Explicaci√≥n
                        st.info(q['explicacion'])
                        
                        # Tip de Memoria
                        if q.get('tip_final'): 
                            st.warning(f"üí° **TIP DE MEMORIA:** {q['tip_final']}")
                        
                        st.session_state.answered = True
                        st.rerun()
                
                # --- L√ìGICA DE SALTO ---
                if skipped:
                    # Bloqueo temporal
                    label_clean = engine.current_article_label.split(" - ")[0]
                    engine.temporary_blacklist.add(label_clean)
                    st.toast(f"Tema bloqueado por esta sesi√≥n: {label_clean}")
                    st.session_state.current_data = None
                    st.rerun()

        # 4. BOT√ìN SIGUIENTE (Fuera del form para evitar recargas raras)
        if st.session_state.answered:
            col_next, col_new = st.columns(2)
            if st.session_state.q_idx < len(q_list) - 1:
                if col_next.button("Siguiente Pregunta ‚û°Ô∏è"):
                    st.session_state.q_idx += 1
                    st.session_state.answered = False
                    st.rerun()
            else:
                if col_new.button("Finalizar Caso y Generar Nuevo üîÑ"): 
                    st.session_state.current_data = None
                    st.session_state.answered = False
                    st.rerun()

    # 5. √ÅREA DE CALIBRACI√ìN (LOS 5 CAPITANES PUROS)
    st.divider()
    with st.expander("üõ†Ô∏è CALIBRACI√ìN DE IA (REPORTAR FALLOS)"):
        st.caption("Ayuda a TIT√ÅN a mejorar. Si la pregunta fue mala, rep√≥rtalo aqu√≠:")
        
        # SOLO LAS 5 OPCIONES CORRECTAS
        reasons_map = {
            "Muy F√°cil": "pregunta_facil",
            "Respuesta Obvia": "respuesta_obvia",
            "Spoiler (Pistas en enunciado)": "spoiler",
            "Desconexi√≥n (Nada que ver)": "desconexion",
            "Opciones Desiguales (Longitud)": "sesgo_longitud"
        }
        
        errs = st.multiselect("Selecciona los fallos:", list(reasons_map.keys()))
        
        if st.button("üì¢ ENVIAR REPORTE Y CASTIGAR IA"):
            for e in errs: 
                engine.feedback_history.append(reasons_map[e])
            st.toast(f"Reporte enviado. La IA ha sido recalibrada con {len(errs)} castigos.", icon="üõ°Ô∏è")
``````python
import streamlit as st
import google.generativeai as genai
import json
import random
import time
import requests
import re
import io
import os
import sys
import subprocess
from collections import Counter

# ==============================================================================
# ==============================================================================
#  ü¶Ö TIT√ÅN v94: SISTEMA JUR√çDICO INTEGRAL (EDICI√ìN SUPREMA)
#  ----------------------------------------------------------------------------
#  ESTE C√ìDIGO ES LA VERSI√ìN DEFINITIVA Y COMPLETA.
#  NO BORRAR NADA. RESPETAR COMENTARIOS Y ESPACIOS.
#
#  CARACTER√çSTICAS T√âCNICAS:
#  1. MOTOR DE INTELIGENCIA SELECTIVA:
#     - Selector de Modo: El usuario define si carga "Norma" o "Gu√≠a".
#     - Segmentaci√≥n Espec√≠fica: Aplica reglas diferentes seg√∫n el tipo.
#     - Filtro Anti-√çndice: Ignora l√≠neas de tabla de contenido (Ej: "Tema ... 5").
#
#  2. GESTI√ìN DE ARCHIVOS:
#     - Lector PDF Nativo (pypdf) integrado y robusto.
#     - Procesador de Texto Manual para copias r√°pidas.
#     - Sistema de Backups JSON completo para guardar progreso.
#
#  3. PEDAGOG√çA Y CALIBRACI√ìN:
#     - Sistema "5 Capitanes" (Calibraci√≥n limpia y directa).
#     - Ordenamiento Natural (1, 2, 10...) en el men√∫ de navegaci√≥n.
#     - Barajador Inteligente de Respuestas para evitar patrones.
# ==============================================================================
# ==============================================================================


# ------------------------------------------------------------------------------
# SECCI√ìN 1: GESTI√ìN DE DEPENDENCIAS Y LIBRER√çAS EXTERNAS
# ------------------------------------------------------------------------------

# A. SISTEMA DE IA NEURONAL (Embeddings)
# Intentamos cargar librer√≠as de IA avanzada para b√∫squeda sem√°ntica.
# Si no est√°n presentes, el sistema usar√° el modo aleatorio (Fail-safe).
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    DL_AVAILABLE = True
    print("‚úÖ Cerebro Neuronal (SentenceTransformers) Activado.")
except ImportError:
    DL_AVAILABLE = False
    print("‚ö†Ô∏è Cerebro Neuronal no detectado. Se usar√° modo aleatorio.")

# B. LECTOR DE ARCHIVOS PDF (CR√çTICO PARA GU√çAS Y MANUALES)
# Intentamos cargar la librer√≠a de lectura de PDFs.
try:
    import pypdf
    PDF_AVAILABLE = True
    print("‚úÖ Lector PDF (pypdf) Activado.")
except ImportError:
    # No forzamos la instalaci√≥n autom√°tica para evitar reinicios, pero avisamos.
    PDF_AVAILABLE = False
    print("‚ö†Ô∏è Lector PDF no detectado. Solo se admitir√° texto manual.")


# ------------------------------------------------------------------------------
# SECCI√ìN 2: CONFIGURACI√ìN VISUAL Y ESTILOS (TU CSS ORIGINAL COMPLETO)
# ------------------------------------------------------------------------------
st.set_page_config(
    page_title="TIT√ÅN v94 - Supremo", 
    page_icon="‚öñÔ∏è", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Inyecci√≥n de CSS avanzado para la interfaz oscura/elegante
st.markdown("""
<style>
    /* 1. Estilo para botones principales en negro elegante */
    .stButton>button {
        width: 100%; 
        border-radius: 8px; 
        font-weight: bold; 
        height: 3.5em; 
        transition: all 0.3s ease-in-out; 
        background-color: #000000; 
        color: #ffffff;
        border: 1px solid #333;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .stButton>button:hover {
        background-color: #333333;
        color: #ffffff;
        transform: scale(1.02);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    /* 2. Caja para la narrativa del caso/norma */
    .narrative-box {
        background-color: #f8f9fa; 
        padding: 30px; 
        border-radius: 12px; 
        border-left: 6px solid #2c3e50; 
        margin-bottom: 25px;
        font-family: 'Georgia', serif; 
        font-size: 1.15em; 
        line-height: 1.6;
        color: #2c3e50;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    /* 3. Etiquetas para art√≠culos fallados (ROJO) */
    .failed-tag {
        background-color: #ffebee; 
        color: #c62828; 
        padding: 6px 12px; 
        border-radius: 20px; 
        font-size: 0.85em; 
        font-weight: 800; 
        margin-right: 6px;
        border: 1px solid #ef9a9a; 
        display: inline-block;
        margin-bottom: 8px;
    }

    /* 4. Etiquetas para art√≠culos dominados (VERDE) */
    .mastered-tag {
        background-color: #e8f5e9; 
        color: #2e7d32; 
        padding: 6px 12px; 
        border-radius: 20px; 
        font-size: 0.85em; 
        font-weight: 800; 
        margin-right: 6px;
        border: 1px solid #a5d6a7; 
        display: inline-block;
        margin-bottom: 8px;
    }
    
    /* 5. Cajas estad√≠sticas del tablero */
    .stat-box {
        text-align: center; 
        padding: 20px; 
        background: #ffffff; 
        border-radius: 12px; 
        border: 1px solid #e0e0e0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    
    /* Ajustes generales de tipograf√≠a */
    h1, h2, h3 {
        font-family: 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #111;
        font-weight: 600;
    }
    
    /* Ajuste para inputs de texto */
    .stTextInput>div>div>input {
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)


# ------------------------------------------------------------------------------
# SECCI√ìN 3: CARGA DEL MODELO DE EMBEDDINGS (CACHEADO)
# ------------------------------------------------------------------------------
@st.cache_resource
def load_embedding_model():
    """
    Carga el modelo vectorial una sola vez al inicio para optimizar rendimiento.
    Esto evita recargas innecesarias cada vez que se pulsa un bot√≥n.
    """
    if DL_AVAILABLE: 
        try:
            # Usamos un modelo ligero y r√°pido
            return SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            # Si falla, retornamos None y el sistema usar√° modo aleatorio
            return None
    return None

dl_model = load_embedding_model()


# ------------------------------------------------------------------------------
# SECCI√ìN 4: LISTA MAESTRA DE ENTIDADES COLOMBIANAS
# ------------------------------------------------------------------------------
ENTIDADES_CO = [
    "Contralor√≠a General de la Rep√∫blica", 
    "Fiscal√≠a General de la Naci√≥n",
    "Procuradur√≠a General de la Naci√≥n", 
    "Defensor√≠a del Pueblo",
    "DIAN", 
    "Registradur√≠a Nacional del Estado Civil", 
    "Consejo Superior de la Judicatura",
    "Corte Suprema de Justicia", 
    "Consejo de Estado", 
    "Corte Constitucional",
    "Polic√≠a Nacional", 
    "Ej√©rcito Nacional", 
    "Instituto Colombiano de Bienestar Familiar (ICBF)", 
    "SENA", 
    "Ministerio de Educaci√≥n Nacional", 
    "Ministerio de Salud y Protecci√≥n Social", 
    "Departamento Administrativo Nacional de Estad√≠stica (DANE)",
    "Superintendencia de Industria y Comercio",
    "Superintendencia Financiera",
    "Comisi√≥n Nacional del Servicio Civil (CNSC)",
    "Otra (Manual) / Agregar +"
]


# ==============================================================================
# ==============================================================================
#  CLASE PRINCIPAL: MOTOR JUR√çDICO TIT√ÅN
#  Esta clase encapsula toda la l√≥gica del negocio.
# ==============================================================================
# ==============================================================================
class LegalEngineTITAN:
    def __init__(self):
        # ---------------------------------------------------------
        # Variables de Almacenamiento de Datos (Estado del Sistema)
        # ---------------------------------------------------------
        self.chunks = []           # Fragmentos de texto procesado
        self.chunk_embeddings = None # Vectores matem√°ticos del texto
        self.mastery_tracker = {}  # Rastreador de dominio por bloque
        self.failed_indices = set() # √çndices de bloques fallados
        self.feedback_history = []  # Historial de calibraci√≥n (Los Capitanes)
        self.current_data = None    # Datos de la pregunta actual en pantalla
        self.current_chunk_idx = -1 # Puntero al bloque actual
        
        # ---------------------------------------------------------
        # Configuraci√≥n de Usuario (Perfil)
        # ---------------------------------------------------------
        self.entity = ""
        self.level = "Profesional" 
        self.simulacro_mode = False
        self.provider = "Unknown" 
        self.api_key = ""
        self.model = None 
        self.current_temperature = 0.3 # Creatividad baja para precisi√≥n t√©cnica
        self.last_failed_embedding = None
        self.doc_type = "Norma" # Variable CR√çTICA: Define si es Ley o Gu√≠a
        
        # ---------------------------------------------------------
        # Variables de Control Pedag√≥gico
        # ---------------------------------------------------------
        self.study_phase = "Pre-Gu√≠a" 
        self.example_question = "" 
        self.job_functions = ""    
        self.thematic_axis = "General"
        self.structure_type = "T√©cnico / Normativo (Sin Caso)" 
        self.questions_per_case = 1 
        
        # ---------------------------------------------------------
        # Mapa de Documento (√çndice Din√°mico)
        # ---------------------------------------------------------
        self.sections_map = {} 
        self.active_section_name = "Todo el Documento"
        
        # ---------------------------------------------------------
        # Sistema Francotirador & Sem√°foro
        # ---------------------------------------------------------
        self.seen_articles = set()      # Art√≠culos ya preguntados en esta sesi√≥n
        self.failed_articles = set()    # Lista Roja (Pendientes de repaso)
        self.mastered_articles = set()  # Lista Verde (Dominados)
        self.temporary_blacklist = set() # Lista Negra (Bot√≥n Saltar)
        self.current_article_label = "General"

    # --------------------------------------------------------------------------
    # M√âTODO: CONFIGURACI√ìN DE API
    # Detecta autom√°ticamente qu√© llave ingres√≥ el usuario.
    # --------------------------------------------------------------------------
    def configure_api(self, key):
        key = key.strip()
        self.api_key = key
        
        if key.startswith("gsk_"):
            self.provider = "Groq"
            return True, "üöÄ Motor GROQ Activado (Velocidad S√≥nica)"
        elif key.startswith("sk-") or key.startswith("sk-proj-"): 
            self.provider = "OpenAI"
            return True, "ü§ñ Motor CHATGPT (GPT-4o) Activado (Precisi√≥n M√°xima)"
        else:
            self.provider = "Google"
            try:
                genai.configure(api_key=key)
                model_list = genai.list_models()
                models = [m.name for m in model_list if 'generateContent' in m.supported_generation_methods]
                
                # Buscamos el mejor modelo disponible (Pro o Flash)
                target = next((m for m in models if 'gemini-1.5-pro' in m), 
                         next((m for m in models if 'flash' in m), models[0]))
                
                self.model = genai.GenerativeModel(target)
                return True, f"üß† Motor GOOGLE ({target}) Activado"
            except Exception as e:
                return False, f"Error con la llave: {str(e)}"

    # --------------------------------------------------------------------------
    # M√âTODO: SEGMENTACI√ìN INTELIGENTE SELECTIVA (EL CEREBRO DEL LECTOR v94)
    # Aqu√≠ aplicamos la l√≥gica separada que pediste: Norma vs Gu√≠a.
    # --------------------------------------------------------------------------
    def smart_segmentation(self, full_text):
        """
        Divide el texto bas√°ndose EXCLUSIVAMENTE en el tipo de documento seleccionado.
        Esto evita que el sistema se confunda tratando de adivinar.
        """
        lineas = full_text.split('\n')
        secciones = {"Todo el Documento": []} 
        
        # Variables de estado para seguimiento de jerarqu√≠a
        active_label = None

        # --- PATRONES REGEX PARA LEYES (NORMA) ---
        p_libro = r'^\s*(LIBRO)\.?\s+[IVXLCDM]+\b'
        p_tit = r'^\s*(T√çTULO|TITULO)\.?\s+[IVXLCDM]+\b' 
        p_cap = r'^\s*(CAP√çTULO|CAPITULO)\.?\s+[IVXLCDM0-9]+\b'
        p_art = r'^\s*(ART√çCULO|ARTICULO|ART)\.?\s*\d+'
        
        # --- PATRONES REGEX PARA GU√çAS (INDICES NUM√âRICOS) ---
        # Detecta: "1. Texto" o "10. Texto"
        p_idx_1 = r'^\s*(\d+)\.\s+([A-Z√Å√â√ç√ì√ö√ë].+)'      
        # Detecta: "1.1 Texto" o "2.3.4 Texto"
        p_idx_2 = r'^\s*(\d+\.\d+)\.?\s+([A-Z√Å√â√ç√ì√ö√ë].+)' 
        
        # --- FILTRO ANTI-√çNDICE (EL CORTAFUEGOS) ---
        # Detecta l√≠neas que terminan en n√∫mero y tienen muchos puntos (Tabla de Contenido)
        # Ej: "5. Desarrollo ........................................... 7"
        p_basura_indice = r'\.{4,}\s*\d+\s*$' 

        for linea in lineas:
            linea_limpia = linea.strip()
            if not linea_limpia: continue
            
            # -------------------------------------------------------
            # CAMINO 1: SI ES UNA GU√çA T√âCNICA O MANUAL
            # -------------------------------------------------------
            if self.doc_type == "Gu√≠a T√©cnica / Manual":
                # 1. Aplicamos el Filtro Anti-√çndice INMEDIATAMENTE
                # Si la l√≠nea tiene "..... 7", se muere aqu√≠.
                if re.search(p_basura_indice, linea_limpia): 
                    continue 
                
                # 2. Buscamos T√≠tulos Num√©ricos (Nivel 1)
                if re.match(p_idx_1, linea_limpia):
                    m = re.match(p_idx_1, linea_limpia)
                    active_label = f"CAP√çTULO {m.group(1)}: {m.group(2)[:80]}"
                    if active_label not in secciones: secciones[active_label] = []
                
                # 3. Buscamos Subt√≠tulos Num√©ricos (Nivel 2)
                elif re.match(p_idx_2, linea_limpia):
                    m = re.match(p_idx_2, linea_limpia)
                    active_label = f"SECCI√ìN {m.group(1)}: {m.group(2)[:80]}"
                    if active_label not in secciones: secciones[active_label] = []

            # -------------------------------------------------------
            # CAMINO 2: SI ES UNA NORMA (LEY, DECRETO, C√ìDIGO)
            # -------------------------------------------------------
            elif self.doc_type == "Norma (Leyes/Decretos)":
                # Aqu√≠ NO aplicamos el filtro anti-√≠ndice tan agresivo.
                
                if re.match(p_libro, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                    
                elif re.match(p_tit, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                    
                elif re.match(p_cap, linea_limpia, re.I):
                    active_label = linea_limpia[:100]
                    secciones[active_label] = []
                
                # Nota: Los art√≠culos se detectan para el "Francotirador", pero no crean una secci√≥n nueva
                # en el men√∫ desplegable para no saturarlo si la ley tiene 500 art√≠culos.

            # -------------------------------------------------------
            # GUARDADO DE DATOS (HERENCIA)
            # -------------------------------------------------------
            # El texto siempre va al "Todo el Documento"
            secciones["Todo el Documento"].append(linea)
            
            # Si hay una etiqueta activa (Cap√≠tulo, T√≠tulo, etc.), guardamos la l√≠nea ah√≠ tambi√©n
            if active_label: 
                secciones[active_label].append(linea)

        # Filtramos secciones vac√≠as o con muy poco texto (ruido)
        return {k: "\n".join(v) for k, v in secciones.items() if len(v) > 20}

    # --------------------------------------------------------------------------
    # M√âTODO: PROCESAMIENTO Y CHUNKING (DIVISI√ìN)
    # --------------------------------------------------------------------------
    def process_law(self, text, axis_name, doc_type_input):
        """
        Prepara el texto para ser consumido por la IA.
        Recibe el TIPO DE DOCUMENTO del usuario.
        """
        text = text.replace('\r', '')
        if len(text) < 100: return 0
        
        self.thematic_axis = axis_name 
        self.doc_type = doc_type_input # Guardamos la elecci√≥n vital (Norma vs Gu√≠a)
        self.sections_map = self.smart_segmentation(text)
        
        # Bloques de 50.000 caracteres (Balance entre contexto y memoria)
        self.chunks = [text[i:i+50000] for i in range(0, len(text), 50000)]
        self.mastery_tracker = {i: 0 for i in range(len(self.chunks))}
        
        if dl_model: 
            with st.spinner("üß† Generando mapa neuronal del documento..."): 
                self.chunk_embeddings = dl_model.encode(self.chunks)
        return len(self.chunks)

    def update_chunks_by_section(self, section_name):
        """
        Permite al usuario estudiar solo una parte espec√≠fica.
        """
        if section_name in self.sections_map:
            texto_seccion = self.sections_map[section_name]
            self.chunks = [texto_seccion[i:i+50000] for i in range(0, len(texto_seccion), 50000)]
            self.mastery_tracker = {i: 0 for i in range(len(self.chunks))}
            self.active_section_name = section_name
            
            if dl_model: 
                self.chunk_embeddings = dl_model.encode(self.chunks)
            
            # Limpieza de memoria temporal
            self.seen_articles.clear()
            self.temporary_blacklist.clear()
            return True
        return False

    # --------------------------------------------------------------------------
    # M√âTODO: ESTAD√çSTICAS
    # --------------------------------------------------------------------------
    def get_stats(self):
        if not self.chunks: return 0, 0, 0
        total = len(self.chunks)
        SCORE_THRESHOLD = 50 
        score = sum([min(v, SCORE_THRESHOLD) for v in self.mastery_tracker.values()])
        perc = int((score / (total * SCORE_THRESHOLD)) * 100) if total > 0 else 0
        return min(perc, 100), len(self.failed_indices), total

    def get_strict_rules(self):
        return "1. NO SPOILERS: La pregunta NO debe dar la respuesta. 2. DEPENDENCIA: Obligatorio leer el texto."

    def get_calibration_instructions(self):
        return """
        INSTRUCCIONES DE FORMATO:
        1. NO REPETIR TEXTO: El 'enunciado' NO debe repetir lo que ya dice la 'narrativa_caso'.
        2. NO CHIVATEAR: No digas "Seg√∫n el punto 2.1". Di "Seg√∫n la gu√≠a".
        """

    # --------------------------------------------------------------------------
    # M√âTODO: GENERADOR DE CASOS (ESTRATEGIA SELECTIVA v94)
    # --------------------------------------------------------------------------
    def generate_case(self):
        """
        El cerebro de la operaci√≥n. 
        Usa el TIPO DE DOCUMENTO para decidir qu√© buscar en el texto.
        """
        if not self.api_key: return {"error": "Falta Llave API"}
        if not self.chunks: return {"error": "Falta Documento Cargado"}
        
        # 1. Selecci√≥n de Bloque (Chunk)
        idx = -1
        # L√≥gica de recuperaci√≥n de errores (Si hay embeddings)
        if self.last_failed_embedding is not None and self.chunk_embeddings is not None and not self.simulacro_mode:
            sims = cosine_similarity([self.last_failed_embedding], self.chunk_embeddings)[0]
            candidatos = [(i, s) for i, s in enumerate(sims) if self.mastery_tracker.get(i, 0) < 3]
            candidatos.sort(key=lambda x: x[1], reverse=True)
            if candidatos: idx = candidatos[0][0]
        
        if idx == -1: idx = random.choice(range(len(self.chunks)))
        
        self.current_chunk_idx = idx
        texto_base = self.chunks[idx]
        
        # 2. ESTRATEGIA DE FRANCOTIRADOR SELECTIVA
        matches = []
        
        if self.doc_type == "Norma (Leyes/Decretos)":
            # ESTRATEGIA A: Buscar "ART√çCULO X" (Para leyes)
            p_art = r'^\s*(?:ART√çCULO|ARTICULO|ART)\.?\s*(\d+[A-Z]?)'
            matches = list(re.finditer(p_art, texto_base, re.I | re.M))
            
        elif self.doc_type == "Gu√≠a T√©cnica / Manual":
            # ESTRATEGIA B: Buscar "√çNDICES NUM√âRICOS" (1., 1.1) (Para Gu√≠as)
            p_idx = r'^\s*(\d+\.\d+|\d+\.)\s+([A-Z√Å√â√ç√ì√ö√ë].+)'
            matches = list(re.finditer(p_idx, texto_base, re.M))

        texto_final_ia = texto_base
        self.current_article_label = "General / Sin Estructura Detectada"
        
        if matches:
            # Filtro Francotirador: Quitar lo ya visto o bloqueado
            candidatos = [m for m in matches if m.group(0).strip() not in self.seen_articles and m.group(0).strip() not in self.temporary_blacklist]
            
            if not candidatos:
                # Si se acabaron los nuevos, repetimos los no bloqueados
                candidatos = [m for m in matches if m.group(0).strip() not in self.temporary_blacklist]
                if not candidatos: 
                    # Si todo est√° bloqueado, reseteamos lista negra
                    candidatos = matches
                    self.temporary_blacklist.clear()
                self.seen_articles.clear()
            
            sel = random.choice(candidatos)
            start = sel.start()
            idx_m = matches.index(sel)
            
            # Cortamos hasta el siguiente elemento para aislar el tema
            end = matches[idx_m+1].start() if idx_m+1 < len(matches) else min(len(texto_base), start+4000)
            
            texto_final_ia = texto_base[start:end] 
            self.current_article_label = sel.group(0).strip()[:60] 
            
            # 3. MICRO-SEGMENTACI√ìN (Universal)
            # Busca listas internas (a, b, c) o numerales internos (1, 2, 3) dentro del bloque seleccionado
            p_sub = r'(^\s*\d+\.\s+|^\s*[a-z]\)\s+|^\s*[A-Z][a-zA-Z\s]{2,50}[:\.])'
            subs = list(re.finditer(p_sub, texto_final_ia, re.M))
            
            if len(subs) > 1:
                s = random.choice(subs)
                s_start = s.start()
                s_end = subs[subs.index(s)+1].start() if subs.index(s)+1 < len(subs) else len(texto_final_ia)
                
                # Le damos contexto + el fragmento espec√≠fico
                texto_final_ia = f"{texto_final_ia[:150]}\n[...]\n{texto_final_ia[s_start:s_end]}"
                self.current_article_label += f" - ITEM {s.group(0).strip()[:10]}..."
        else:
            self.current_article_label = "General"
            texto_final_ia = texto_base[:4000]

        # 4. CONFIGURACI√ìN DE LOS 5 CAPITANES (CALIBRACI√ìN)
        feed_instr = ""
        if self.feedback_history:
            last = self.feedback_history[-5:]
            corr = []
            
            if "pregunta_facil" in last: 
                corr.append("ALERTA CR√çTICA: El usuario se aburre. AUMENTAR DRASTICAMENTE DIFICULTAD.")
            if "respuesta_obvia" in last: 
                corr.append("ALERTA CR√çTICA: Respuestas obvias detectadas. USAR TRAMPAS L√ìGICAS.")
            if "spoiler" in last: 
                corr.append("ALERTA CR√çTICA: Spoilers detectados. SIN PISTAS EN ENUNCIADO.")
            if "desconexion" in last: 
                corr.append("ALERTA CR√çTICA: Pregunta desconectada. APEGARSE AL TEXTO AL 100%.")
            if "sesgo_longitud" in last: 
                corr.append("ALERTA CR√çTICA: Patr√≥n de longitud detectado. EQUILIBRAR OPCIONES.")
            
            if corr: feed_instr = "CORRECCIONES PRIORITARIAS DEL USUARIO: " + " ".join(corr)

        # 5. CONSTRUCCI√ìN DEL PROMPT FINAL
        prompt = f"""
        ACT√öA COMO EXPERTO EN CONCURSOS (NIVEL {self.level.upper()}). 
        ENTIDAD: {self.entity.upper()}.
        TIPO DE DOCUMENTO: {self.doc_type.upper()}.
        ESTILO: {self.structure_type}.
        {feed_instr}
        
        Genera {self.questions_per_case} preguntas (A,B,C,D) bas√°ndote EXCLUSIVAMENTE en el texto proporcionado.
        
        TEXTO DE ESTUDIO:
        "{texto_final_ia}"
        
        REGLAS DE ORO:
        1. 4 OPCIONES (A,B,C,D). Una sola correcta.
        2. EXPLICACI√ìN DETALLADA por opci√≥n (Por qu√© es correcta y por qu√© las otras no).
        3. TIP MEMORIA: Mnemotecnia corta o palabra clave.
        
        EJEMPLO DE ESTILO A COPIAR: 
        '''{self.example_question}'''
        
        FORMATO JSON OBLIGATORIO:
        {{
            "articulo_fuente": "REFERENCIA EXACTA (Ej: Art 5 o Punto 2.1)",
            "narrativa_caso": "Contexto situacional o normativo...",
            "preguntas": [
                {{
                    "enunciado": "...", 
                    "opciones": {{
                        "A": "...",
                        "B": "...",
                        "C": "...",
                        "D": "..."
                    }}, 
                    "respuesta": "A", 
                    "tip_memoria": "...", 
                    "explicaciones": {{
                        "A": "...",
                        "B": "...",
                        "C": "...",
                        "D": "..."
                    }}
                }}
            ]
        }}
        """
        
        # 6. LLAMADA A LA API (CON SISTEMA DE REINTENTOS)
        attempts = 0
        while attempts < 3:
            try:
                # Proveedor OpenAI
                if self.provider == "OpenAI":
                    h = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
                    d = {"model": "gpt-4o", "messages": [{"role":"system","content":"JSON ONLY"},{"role":"user","content":prompt}], "response_format": {"type": "json_object"}}
                    r = requests.post("[https://api.openai.com/v1/chat/completions](https://api.openai.com/v1/chat/completions)", headers=h, json=d)
                    txt_resp = r.json()['choices'][0]['message']['content']
                
                # Proveedor Google
                elif self.provider == "Google":
                    res = self.model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
                    txt_resp = res.text.strip()
                
                # Proveedor Groq
                else: 
                    h = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
                    d = {"model": "llama-3.3-70b-versatile", "messages": [{"role":"system","content":"JSON ONLY"},{"role":"user","content":prompt}]}
                    r = requests.post("[https://api.groq.com/openai/v1/chat/completions](https://api.groq.com/openai/v1/chat/completions)", headers=h, json=d)
                    txt_resp = r.json()['choices'][0]['message']['content']

                # Limpieza de Markdown (Si la IA responde con ```json ... ```)
                if "```" in txt_resp: 
                    match = re.search(r'```(?:json)?(.*?)```', txt_resp, re.DOTALL)
                    if match: txt_resp = match.group(1).strip()
                
                final_json = json.loads(txt_resp)
                
                # Actualizar etiqueta si la IA detect√≥ mejor la fuente
                if "articulo_fuente" in final_json and "ITEM" not in self.current_article_label:
                    # Si la etiqueta actual es gen√©rica, adoptamos la de la IA
                    if "General" in self.current_article_label:
                        self.current_article_label = final_json["articulo_fuente"].upper()

                # BARAJADOR INTELIGENTE (SHUFFLE)
                # Esto evita que la respuesta correcta sea siempre la 'A' o la 'C'
                for q in final_json['preguntas']:
                    ops = list(q['opciones'].items())
                    ans_txt = q['opciones'][q['respuesta']]
                    exps = q.get('explicaciones', {})
                    
                    # Creamos objetos completos antes de barajar
                    items = [{"t":v, "e":exps.get(k,"."), "ok":(v==ans_txt)} for k,v in ops]
                    random.shuffle(items)
                    
                    new_ops = {}
                    new_ans = "A"
                    exp_txt = ""
                    lets = ['A','B','C','D']
                    
                    for i, it in enumerate(items):
                        if i < 4:
                            l = lets[i]
                            new_ops[l] = it["t"]
                            if it["ok"]: new_ans = l
                            
                            icon = "‚úÖ CORRECTA" if it["ok"] else "‚ùå INCORRECTA"
                            exp_txt += f"**({l}) {icon}:** {it['e']}\n\n"
                    
                    q['opciones'] = new_ops
                    q['respuesta'] = new_ans
                    q['explicacion'] = exp_txt
                    q['tip_final'] = q.get('tip_memoria', "")
                
                return final_json
            except Exception as e: 
                time.sleep(1)
                attempts += 1
        
        return {"error": "Servidor Saturado o Error de JSON. Por favor, reintenta."}


# ==============================================================================
# ==============================================================================
#  INTERFAZ DE USUARIO (FRONTEND STREAMLIT)
#  Aqu√≠ se construye la p√°gina web visible.
# ==============================================================================
# ==============================================================================
if 'engine' not in st.session_state: st.session_state.engine = LegalEngineTITAN()
if 'case_id' not in st.session_state: st.session_state.case_id = 0
if 'page' not in st.session_state: st.session_state.page = 'setup'
if 'q_idx' not in st.session_state: st.session_state.q_idx = 0
if 'answered' not in st.session_state: st.session_state.answered = False
engine = st.session_state.engine

# --- BARRA LATERAL (CONFIGURACI√ìN) ---
with st.sidebar:
    st.title("ü¶Ö TIT√ÅN v94 (Selectivo)")
    st.caption("Sistema de Entrenamiento Jur√≠dico Integral")
    
    with st.expander("üîë LLAVE MAESTRA (API KEY)", expanded=True):
        key = st.text_input("Ingresa tu Key (Google/OpenAI):", type="password")
        if key:
            ok, msg = engine.configure_api(key)
            if ok: st.success(msg)
            else: st.error(msg)
    
    st.divider()
    
    # --- SELECTOR DE MODO (NUEVO EN v94) ---
    st.markdown("### üìÇ TIPO DE DOCUMENTO")
    doc_type_sel = st.radio(
        "¬øQu√© vas a estudiar?", 
        ["Norma (Leyes/Decretos)", "Gu√≠a T√©cnica / Manual"],
        help="Define c√≥mo TIT√ÅN leer√° el archivo. Norma busca Art√≠culos. Gu√≠a busca Numerales.",
        index=0
    )
    
    st.divider()

    # --- NAVEGACI√ìN (MAPA) ---
    if engine.sections_map:
        st.markdown("### üìç MAPA DEL DOCUMENTO")
        
        # ORDENAMIENTO NATURAL (1, 2, 10... y no 1, 10, 2)
        opciones_mapa = list(engine.sections_map.keys())
        if "Todo el Documento" in opciones_mapa: opciones_mapa.remove("Todo el Documento")
        
        def natural_keys(text):
            return [int(c) if c.isdigit() else c for c in re.split(r'(\d+)', text)]
        
        opciones_mapa.sort(key=natural_keys)
        opciones_mapa.insert(0, "Todo el Documento")
        
        try: idx_sec = opciones_mapa.index(engine.active_section_name)
        except: idx_sec = 0
            
        sel = st.selectbox("Saltar a secci√≥n:", opciones_mapa, index=idx_sec)
        
        if sel != engine.active_section_name: 
            engine.update_chunks_by_section(sel)
            st.toast(f"Enfoque cambiado a: {sel}", icon="üó∫Ô∏è")
            st.rerun()

    st.divider()

    # --- PESTA√ëAS DE CARGA ---
    t1, t2 = st.tabs(["üìù NUEVO DOCUMENTO", "üìÇ CARGAR BACKUP"])
    
    with t1:
        txt_pdf = ""
        # 1. CARGA DE PDF (INTEGRADA)
        if PDF_AVAILABLE:
            pdf = st.file_uploader("Subir PDF (Gu√≠a/Ley/Manual):", type=['pdf'])
            if pdf:
                try:
                    with st.spinner("üìÑ Extrayendo texto..."):
                        reader = pypdf.PdfReader(pdf)
                        for p in reader.pages: txt_pdf += p.extract_text() + "\n"
                        st.success(f"¬°Le√≠do! {len(reader.pages)} p√°ginas.")
                except Exception as e: st.error(f"Error PDF: {e}")
        else:
            st.warning("‚ö†Ô∏è Librer√≠a 'pypdf' no instalada. Solo texto manual.")
        
        # 2. CARGA MANUAL
        st.caption("O pega el texto aqu√≠:")
        txt_manual = st.text_area("Texto Manual:", height=100)
        axis = st.text_input("Tema / Eje Tem√°tico (Ej: Gu√≠a Auditor√≠a):", value=engine.thematic_axis)
        
        if st.button("üöÄ PROCESAR DOCUMENTO"):
            final = txt_pdf if txt_pdf else txt_manual
            # Pasamos el TIPO DE DOCUMENTO al procesador
            if engine.process_law(final, axis, doc_type_sel): 
                st.session_state.page = 'game'
                st.session_state.current_data = None
                st.success(f"¬°Procesado como {doc_type_sel}!")
                time.sleep(1)
                st.rerun()

    with t2:
        # 3. CARGA DE BACKUP (JSON)
        upl = st.file_uploader("Subir Backup (.json):", type=['json'])
        if upl:
            try:
                d = json.load(upl)
                engine.chunks = d['chunks']
                engine.mastery_tracker = {int(k):v for k,v in d['mastery'].items()}
                # Recuperamos listas
                engine.failed_articles = set(d.get('failed_arts', []))
                engine.mastered_articles = set(d.get('mastered_arts', []))
                st.success("Backup Restaurado")
                time.sleep(1)
                st.session_state.page = 'game'
                st.session_state.current_data = None
                st.rerun()
            except: st.error("Archivo corrupto")
    
    # --- BOT√ìN DE INICIO DE SIMULACRO ---
    if engine.chunks and st.session_state.page == 'setup':
        st.divider()
        if st.button("‚ñ∂Ô∏è INICIAR ENTRENAMIENTO", type="primary"): 
            st.session_state.page = 'game'
            st.session_state.current_data = None
            st.rerun()
            
    # --- BOT√ìN DE GUARDADO ---
    if engine.chunks:
        st.divider()
        # Preparamos datos para guardar
        save_data = {
            "chunks": engine.chunks,
            "mastery": engine.mastery_tracker,
            "failed_arts": list(engine.failed_articles),
            "mastered_arts": list(engine.mastered_articles)
        }
        st.download_button("üíæ Guardar Progreso", json.dumps(save_data), "backup_titan.json")


# --- PANTALLA PRINCIPAL (JUEGO) ---
if st.session_state.page == 'game':
    # 1. M√âTRICAS SUPERIORES
    p, f, t = engine.get_stats()
    
    st.info(f"üéØ FOCO ACTUAL: **{engine.current_article_label}**")
    
    c1, c2, c3 = st.columns(3)
    c1.metric("Dominio Total", f"{p}%")
    c2.metric("Fallos Acumulados", f"{f}")
    c3.metric("Bloques Estudiados", f"{len([x for x in engine.mastery_tracker.values() if x>0])}/{t}")
    st.progress(p/100)

    # 2. GENERACI√ìN DE PREGUNTA (Si no hay activa)
    if not st.session_state.get('current_data'):
        with st.spinner("ü§ñ Analizando documento y generando caso..."):
            d = engine.generate_case()
            if "error" in d: 
                st.error(d['error'])
                if st.button("Reintentar"): st.rerun()
            else: 
                st.session_state.current_data = d
                st.session_state.case_id += 1
                st.session_state.q_idx = 0
                st.session_state.answered = False
                st.rerun()

    # 3. VISUALIZACI√ìN DE LA PREGUNTA
    d = st.session_state.current_data
    
    # Caja de Narrativa
    st.markdown(f"<div class='narrative-box'><h4>üìú Contexto</h4>{d.get('narrativa_caso','...')}</div>", unsafe_allow_html=True)
    
    if d.get('preguntas'):
        q_list = d['preguntas']
        if st.session_state.q_idx < len(q_list):
            q = q_list[st.session_state.q_idx]
            
            with st.form(key=f"form_{st.session_state.case_id}_{st.session_state.q_idx}"):
                st.write(f"### {q['enunciado']}")
                
                # Opciones de Radio
                # Usamos una lista de opciones pre-barajadas desde la generaci√≥n
                opciones_visuales = [f"{k}) {v}" for k, v in q['opciones'].items()]
                sel = st.radio("Selecciona una opci√≥n:", opciones_visuales)
                
                c_val, c_skip = st.columns([1,1])
                submitted = c_val.form_submit_button("‚úÖ VALIDAR RESPUESTA")
                skipped = c_skip.form_submit_button("‚è≠Ô∏è SALTAR TEMA (Bloquear)")
                
                # --- L√ìGICA DE VALIDACI√ìN ---
                if submitted:
                    if not sel:
                        st.warning("Debes seleccionar una opci√≥n.")
                    else:
                        letra_seleccionada = sel.split(")")[0]
                        if letra_seleccionada == q['respuesta']: 
                            st.success("üéâ ¬°CORRECTO! Has dominado este punto.")
                            engine.mastery_tracker[engine.current_chunk_idx] += 1
                            
                            tag = f"[{engine.thematic_axis}] {engine.current_article_label}"
                            if "General" not in tag: 
                                engine.failed_articles.discard(tag)
                                engine.mastered_articles.add(tag)
                        else: 
                            st.error(f"‚ùå INCORRECTO. La respuesta correcta era la opci√≥n {q['respuesta']}.")
                            engine.failed_indices.add(engine.current_chunk_idx)
                            
                            # Guardamos vector de error si hay modelo
                            if engine.chunk_embeddings is not None:
                                engine.last_failed_embedding = engine.chunk_embeddings[engine.current_chunk_idx]
                            
                            tag = f"[{engine.thematic_axis}] {engine.current_article_label}"
                            if "General" not in tag: 
                                engine.mastered_articles.discard(tag)
                                engine.failed_articles.add(tag)
                        
                        # Explicaci√≥n
                        st.info(q['explicacion'])
                        
                        # Tip de Memoria
                        if q.get('tip_final'): 
                            st.warning(f"üí° **TIP DE MEMORIA:** {q['tip_final']}")
                        
                        st.session_state.answered = True
                        st.rerun()
                
                # --- L√ìGICA DE SALTO ---
                if skipped:
                    # Bloqueo temporal
                    label_clean = engine.current_article_label.split(" - ")[0]
                    engine.temporary_blacklist.add(label_clean)
                    st.toast(f"Tema bloqueado por esta sesi√≥n: {label_clean}")
                    st.session_state.current_data = None
                    st.rerun()

        # 4. BOT√ìN SIGUIENTE (Fuera del form para evitar recargas raras)
        if st.session_state.answered:
            col_next, col_new = st.columns(2)
            if st.session_state.q_idx < len(q_list) - 1:
                if col_next.button("Siguiente Pregunta ‚û°Ô∏è"):
                    st.session_state.q_idx += 1
                    st.session_state.answered = False
                    st.rerun()
            else:
                if col_new.button("Finalizar Caso y Generar Nuevo üîÑ"): 
                    st.session_state.current_data = None
                    st.session_state.answered = False
                    st.rerun()

    # 5. √ÅREA DE CALIBRACI√ìN (LOS 5 CAPITANES PUROS)
    st.divider()
    with st.expander("üõ†Ô∏è CALIBRACI√ìN DE IA (REPORTAR FALLOS)"):
        st.caption("Ayuda a TIT√ÅN a mejorar. Si la pregunta fue mala, rep√≥rtalo aqu√≠:")
        
        # SOLO LAS 5 OPCIONES CORRECTAS
        reasons_map = {
            "Muy F√°cil": "pregunta_facil",
            "Respuesta Obvia": "respuesta_obvia",
            "Spoiler (Pistas en enunciado)": "spoiler",
            "Desconexi√≥n (Nada que ver)": "desconexion",
            "Opciones Desiguales (Longitud)": "sesgo_longitud"
        }
        
        errs = st.multiselect("Selecciona los fallos:", list(reasons_map.keys()))
        
        if st.button("üì¢ ENVIAR REPORTE Y CASTIGAR IA"):
            for e in errs: 
                engine.feedback_history.append(reasons_map[e])
            st.toast(f"Reporte enviado. La IA ha sido recalibrada con {len(errs)} castigos.", icon="üõ°Ô∏è")